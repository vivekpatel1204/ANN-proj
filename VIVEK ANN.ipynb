{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db0240b1-7c57-4489-9040-f5d836e23cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdfe86e3-da3e-4e40-9786-a64098d54efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=pd.read_csv(\"hindi_eng.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54669c59-e220-4391-ad38-3a95189180ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "tides        50000\n",
       "ted          39881\n",
       "indic2012    37726\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a588dbd3-e088-4bc1-9d9f-2c0fe7561fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ted</td>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted</td>\n",
       "      <td>I'd like to tell you about one such child,</td>\n",
       "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>This percentage is even greater than the perce...</td>\n",
       "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted</td>\n",
       "      <td>what we really mean is that they're bad at not...</td>\n",
       "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>.The ending portion of these Vedas is called U...</td>\n",
       "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tides</td>\n",
       "      <td>The then Governor of Kashmir resisted transfer...</td>\n",
       "      <td>कश्मीर के तत्कालीन गवर्नर ने इस हस्तांतरण का व...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>In this lies the circumstances of people befor...</td>\n",
       "      <td>इसमें तुमसे पूर्व गुज़रे हुए लोगों के हालात हैं।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ted</td>\n",
       "      <td>And who are we to say, even, that they are wrong</td>\n",
       "      <td>और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>“”Global Warming“” refer to warming caused in ...</td>\n",
       "      <td>ग्लोबल वॉर्मिंग से आशय हाल ही के दशकों में हुई...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tides</td>\n",
       "      <td>You may want your child to go to a school that...</td>\n",
       "      <td>हो सकता है कि आप चाहते हों कि आप का नऋर्नमेनटे...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tides</td>\n",
       "      <td>Please ensure that you use the appropriate form .</td>\n",
       "      <td>कृपया यह सुनिश्चित कर लें कि आप सही फॉर्म का प...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>Category: Religious Text</td>\n",
       "      <td>श्रेणी:धर्मग्रन्थ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>This period summarily is pepped up with devotion.</td>\n",
       "      <td>यह काल समग्रतः भक्ति भावना से ओतप्रोत काल है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ted</td>\n",
       "      <td>So there is some sort of justice</td>\n",
       "      <td>तो वहाँ न्याय है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tides</td>\n",
       "      <td>The first two were found unreliable and the pr...</td>\n",
       "      <td>पहले दो को अविश्वसनीय मानकर बाकी पांच मुखबिरों...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tides</td>\n",
       "      <td>They had justified their educational policy of...</td>\n",
       "      <td>कम संख़्या वाले उच्च एवं मध्यम श्रेणी के लोगों...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>And now at present the naturecure, Ayurvedic a...</td>\n",
       "      <td>हाल में नेपाल के हस्पताल सामन्यतया आयुर्वेद, प...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>Parliament time frame is 5 years and this will...</td>\n",
       "      <td>लोकसभा की कार्यावधि 5 वर्ष है पर्ंतु इसे समय स...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tides</td>\n",
       "      <td>ii Register Courts , empowered to try causes f...</td>\n",
       "      <td>रजिस्टर न्यायालय जिन्हें न्यायाधीश द्वारा प्रा...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>Extreme weather due to increased mortality; di...</td>\n",
       "      <td>बढ़ती हुई मौतों displacements और आर्थिक नुकसान...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                   english_sentence  \\\n",
       "0         ted  politicians do not have permission to do what ...   \n",
       "1         ted         I'd like to tell you about one such child,   \n",
       "2   indic2012  This percentage is even greater than the perce...   \n",
       "3         ted  what we really mean is that they're bad at not...   \n",
       "4   indic2012  .The ending portion of these Vedas is called U...   \n",
       "5       tides  The then Governor of Kashmir resisted transfer...   \n",
       "6   indic2012  In this lies the circumstances of people befor...   \n",
       "7         ted   And who are we to say, even, that they are wrong   \n",
       "8   indic2012  “”Global Warming“” refer to warming caused in ...   \n",
       "9       tides  You may want your child to go to a school that...   \n",
       "10      tides  Please ensure that you use the appropriate form .   \n",
       "11  indic2012                           Category: Religious Text   \n",
       "12  indic2012  This period summarily is pepped up with devotion.   \n",
       "13        ted                   So there is some sort of justice   \n",
       "14      tides  The first two were found unreliable and the pr...   \n",
       "15      tides  They had justified their educational policy of...   \n",
       "16  indic2012  And now at present the naturecure, Ayurvedic a...   \n",
       "17  indic2012  Parliament time frame is 5 years and this will...   \n",
       "18      tides  ii Register Courts , empowered to try causes f...   \n",
       "19  indic2012  Extreme weather due to increased mortality; di...   \n",
       "\n",
       "                                       hindi_sentence  \n",
       "0   राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
       "1   मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
       "2    यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
       "3      हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
       "4         इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  \n",
       "5   कश्मीर के तत्कालीन गवर्नर ने इस हस्तांतरण का व...  \n",
       "6    इसमें तुमसे पूर्व गुज़रे हुए लोगों के हालात हैं।  \n",
       "7    और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं  \n",
       "8   ग्लोबल वॉर्मिंग से आशय हाल ही के दशकों में हुई...  \n",
       "9   हो सकता है कि आप चाहते हों कि आप का नऋर्नमेनटे...  \n",
       "10  कृपया यह सुनिश्चित कर लें कि आप सही फॉर्म का प...  \n",
       "11                                  श्रेणी:धर्मग्रन्थ  \n",
       "12      यह काल समग्रतः भक्ति भावना से ओतप्रोत काल है।  \n",
       "13                                   तो वहाँ न्याय है  \n",
       "14  पहले दो को अविश्वसनीय मानकर बाकी पांच मुखबिरों...  \n",
       "15  कम संख़्या वाले उच्च एवं मध्यम श्रेणी के लोगों...  \n",
       "16  हाल में नेपाल के हस्पताल सामन्यतया आयुर्वेद, प...  \n",
       "17  लोकसभा की कार्यावधि 5 वर्ष है पर्ंतु इसे समय स...  \n",
       "18  रजिस्टर न्यायालय जिन्हें न्यायाधीश द्वारा प्रा...  \n",
       "19  बढ़ती हुई मौतों displacements और आर्थिक नुकसान...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b184f090-8c7b-4ba9-9622-e07aef67c857",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f09c999-e4ae-4b67-9599-244810f275c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source              0\n",
       "english_sentence    2\n",
       "hindi_sentence      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(lines).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f10fb43-bf80-424e-8b44-d9a5f23d59bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=lines[~pd.isnull(lines['english_sentence'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afa76249-0120-465b-a946-1395551ed81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da74ced4-66ff-4655-81f7-6b476d547780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pick 25000 lines\n",
    "lines=lines.sample(n=25000,random_state=42)\n",
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5745d46-a3d1-49cd-b2ea-a8dc67cfcb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase all characters\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.lower())\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbe70d26-133d-40bf-84ae-280dd15171d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove quotes\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fbc3a87-801d-42a5-83a8-a1aa8e99a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "# Remove all the special characters\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41e3b660-7710-49e6-b30e-241f0ec3cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "# Remove extra spaces\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.strip())\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.strip())\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ef9d661-7cf2-4bf4-aca0-516d40d26e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add start and end tokens to target sequences\n",
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96c74291-caf6-4d31-96e1-66758b5ad2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25520</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>islam is word from arabic and it full word is ...</td>\n",
       "      <td>START_ इस्लाम शब्द अरबी भाषा का शब्द है जिसका ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118633</th>\n",
       "      <td>ted</td>\n",
       "      <td>everything is reliant on these computers working</td>\n",
       "      <td>START_ इन कंप्यूटरों पर सब कुछ निर्भर है _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113495</th>\n",
       "      <td>tides</td>\n",
       "      <td>parliament does not control the government</td>\n",
       "      <td>START_ संसद का सरकार पपर नियंत्रण नपहीं रहता _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29783</th>\n",
       "      <td>tides</td>\n",
       "      <td>race equality new laws</td>\n",
       "      <td>START_ नये कानून नस्ली समानता _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111804</th>\n",
       "      <td>tides</td>\n",
       "      <td>the provision would not affect the power of pa...</td>\n",
       "      <td>START_ व्यवसायों आदि से होने वाली आय के बारे म...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           source                                   english_sentence  \\\n",
       "25520   indic2012  islam is word from arabic and it full word is ...   \n",
       "118633        ted   everything is reliant on these computers working   \n",
       "113495      tides         parliament does not control the government   \n",
       "29783       tides                             race equality new laws   \n",
       "111804      tides  the provision would not affect the power of pa...   \n",
       "\n",
       "                                           hindi_sentence  \n",
       "25520   START_ इस्लाम शब्द अरबी भाषा का शब्द है जिसका ...  \n",
       "118633      START_ इन कंप्यूटरों पर सब कुछ निर्भर है _END  \n",
       "113495  START_ संसद का सरकार पपर नियंत्रण नपहीं रहता _END  \n",
       "29783                  START_ नये कानून नस्ली समानता _END  \n",
       "111804  START_ व्यवसायों आदि से होने वाली आय के बारे म...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80318a08-0d7e-4e99-afcd-7e6321dbebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get English and Hindi Vocabulary\n",
    "all_eng_words=set()\n",
    "for eng in lines['english_sentence']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "all_hindi_words=set()\n",
    "for hin in lines['hindi_sentence']:\n",
    "    for word in hin.split():\n",
    "        if word not in all_hindi_words:\n",
    "            all_hindi_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad7bf59c-2707-4da3-824f-732aafe2c1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30899"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_eng_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d0e1741-823c-47da-85c5-67e82d5dcb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36900"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_hindi_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8de46e60-4cee-4d7e-b03e-04438d022408",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines['length_eng_sentence']=lines['english_sentence'].apply(lambda x:len(x.split(\" \")))\n",
    "lines['length_hin_sentence']=lines['hindi_sentence'].apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "309710e4-29b9-42c5-91a8-f1aa83f41cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25520</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>islam is word from arabic and it full word is ...</td>\n",
       "      <td>START_ इस्लाम शब्द अरबी भाषा का शब्द है जिसका ...</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118633</th>\n",
       "      <td>ted</td>\n",
       "      <td>everything is reliant on these computers working</td>\n",
       "      <td>START_ इन कंप्यूटरों पर सब कुछ निर्भर है _END</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113495</th>\n",
       "      <td>tides</td>\n",
       "      <td>parliament does not control the government</td>\n",
       "      <td>START_ संसद का सरकार पपर नियंत्रण नपहीं रहता _END</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29783</th>\n",
       "      <td>tides</td>\n",
       "      <td>race equality new laws</td>\n",
       "      <td>START_ नये कानून नस्ली समानता _END</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111804</th>\n",
       "      <td>tides</td>\n",
       "      <td>the provision would not affect the power of pa...</td>\n",
       "      <td>START_ व्यवसायों आदि से होने वाली आय के बारे म...</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           source                                   english_sentence  \\\n",
       "25520   indic2012  islam is word from arabic and it full word is ...   \n",
       "118633        ted   everything is reliant on these computers working   \n",
       "113495      tides         parliament does not control the government   \n",
       "29783       tides                             race equality new laws   \n",
       "111804      tides  the provision would not affect the power of pa...   \n",
       "\n",
       "                                           hindi_sentence  \\\n",
       "25520   START_ इस्लाम शब्द अरबी भाषा का शब्द है जिसका ...   \n",
       "118633      START_ इन कंप्यूटरों पर सब कुछ निर्भर है _END   \n",
       "113495  START_ संसद का सरकार पपर नियंत्रण नपहीं रहता _END   \n",
       "29783                  START_ नये कानून नस्ली समानता _END   \n",
       "111804  START_ व्यवसायों आदि से होने वाली आय के बारे म...   \n",
       "\n",
       "        length_eng_sentence  length_hin_sentence  \n",
       "25520                    14                   21  \n",
       "118633                    7                    9  \n",
       "113495                    6                    9  \n",
       "29783                     4                    6  \n",
       "111804                   22                   24  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "383a0b80-cb11-43e2-869d-6da2c7fcec5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2463, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[lines['length_eng_sentence']>30].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b18c8606-38d7-4e6f-a397-cc3ab97cc3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=lines[lines['length_eng_sentence']<=20]\n",
    "lines=lines[lines['length_hin_sentence']<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1eb0d4b7-5ca6-4fea-b6ab-a6aa5611b26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6181f613-db5f-480b-8343-050727d54ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of Hindi Sentence  20\n",
      "maximum length of English Sentence  20\n"
     ]
    }
   ],
   "source": [
    "print(\"maximum length of Hindi Sentence \",max(lines['length_hin_sentence']))\n",
    "print(\"maximum length of English Sentence \",max(lines['length_eng_sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56d17c32-59e0-4e5f-b32b-1d79ca13e2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_src=max(lines['length_hin_sentence'])\n",
    "max_length_tar=max(lines['length_eng_sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ca6c4e-231d-4dc4-9a8a-803381a82f88",
   "metadata": {},
   "source": [
    "MODEL ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9202ce05-44d9-4a0a-8ec6-4c3ea64f694e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30899, 36900)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_hindi_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_hindi_words)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76e02809-7283-40a7-a59e-72ca39599139",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_decoder_tokens += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fa1452f-87fd-4361-a385-6c6bd3e5e2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b134ead9-bf9e-466b-a868-f0d93e7d4521",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "390fecb6-2aa8-4a10-8cc0-40bda703890a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39869</th>\n",
       "      <td>ted</td>\n",
       "      <td>your call your call</td>\n",
       "      <td>START_ आपका चुनाव आपका चुनाव _END</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109633</th>\n",
       "      <td>ted</td>\n",
       "      <td>my lab and others have done dozens of studies</td>\n",
       "      <td>START_ मेरी प्रयोगशाला में और बाके दर्ज़नों जग...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10869</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>he helped also those coming iran in this manner</td>\n",
       "      <td>START_ इसी प्रकार उसने ईरान से आने वालों को भी...</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39734</th>\n",
       "      <td>ted</td>\n",
       "      <td>its also if you look very closely</td>\n",
       "      <td>START_ बल्कि अगर आप गौर से देखे _END</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19859</th>\n",
       "      <td>ted</td>\n",
       "      <td>and our ability to connect with each other reg...</td>\n",
       "      <td>START_ भोगौलिकता की सीमा के परे एक दूसरे से जु...</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25593</th>\n",
       "      <td>tides</td>\n",
       "      <td>next mseb buys no more than per cent of dabhol...</td>\n",
       "      <td>START_ फिर महाराष्ट्र बिजली बोर्ड़ ड़ीपीसी की ...</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90811</th>\n",
       "      <td>ted</td>\n",
       "      <td>of this whole collective socialization</td>\n",
       "      <td>START_ की आधारशिला पर व्यवहार करते हैं _END</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5447</th>\n",
       "      <td>tides</td>\n",
       "      <td>nor is it any the less interesting as a novel</td>\n",
       "      <td>START_ और यह सब किसी उपन्यास से कम रोचक भी न ह...</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102126</th>\n",
       "      <td>ted</td>\n",
       "      <td>that is my invention</td>\n",
       "      <td>START_ ये मेरी खोज है _END</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50801</th>\n",
       "      <td>tides</td>\n",
       "      <td>today the museum only takes specimens from the...</td>\n",
       "      <td>START_ आज संग्रहालय वन्य जगत से तभी नमूने लेता...</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           source                                   english_sentence  \\\n",
       "39869         ted                                your call your call   \n",
       "109633        ted      my lab and others have done dozens of studies   \n",
       "10869   indic2012    he helped also those coming iran in this manner   \n",
       "39734         ted                  its also if you look very closely   \n",
       "19859         ted  and our ability to connect with each other reg...   \n",
       "25593       tides  next mseb buys no more than per cent of dabhol...   \n",
       "90811         ted             of this whole collective socialization   \n",
       "5447        tides      nor is it any the less interesting as a novel   \n",
       "102126        ted                               that is my invention   \n",
       "50801       tides  today the museum only takes specimens from the...   \n",
       "\n",
       "                                           hindi_sentence  \\\n",
       "39869                   START_ आपका चुनाव आपका चुनाव _END   \n",
       "109633  START_ मेरी प्रयोगशाला में और बाके दर्ज़नों जग...   \n",
       "10869   START_ इसी प्रकार उसने ईरान से आने वालों को भी...   \n",
       "39734                START_ बल्कि अगर आप गौर से देखे _END   \n",
       "19859   START_ भोगौलिकता की सीमा के परे एक दूसरे से जु...   \n",
       "25593   START_ फिर महाराष्ट्र बिजली बोर्ड़ ड़ीपीसी की ...   \n",
       "90811         START_ की आधारशिला पर व्यवहार करते हैं _END   \n",
       "5447    START_ और यह सब किसी उपन्यास से कम रोचक भी न ह...   \n",
       "102126                         START_ ये मेरी खोज है _END   \n",
       "50801   START_ आज संग्रहालय वन्य जगत से तभी नमूने लेता...   \n",
       "\n",
       "        length_eng_sentence  length_hin_sentence  \n",
       "39869                     4                    6  \n",
       "109633                    9                   10  \n",
       "10869                     9                   14  \n",
       "39734                     7                    8  \n",
       "19859                    11                   18  \n",
       "25593                    12                   13  \n",
       "90811                     5                    8  \n",
       "5447                     10                   13  \n",
       "102126                    4                    6  \n",
       "50801                    16                   19  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = shuffle(lines)\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f51d1b05-7ccb-4ecb-a96c-82e7cce36afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13209,), (3303,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = lines['english_sentence'], lines['hindi_sentence']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32c25335-9af2-4bfd-a860-4efbd22dfe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle('X_train.pkl')\n",
    "X_test.to_pickle('X_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df17ee20-8553-466b-bf2b-bd271bcf2f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2448e493-731a-48b3-b8f3-68514feaf56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5d3c62d-1804-449f-94d3-4cacedfacffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a95e728b-219b-472d-90ed-966c1121c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7114101a-7ba1-48e1-a43d-d3b2e0b2c30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9989b524-dcd4-4a6d-aeb2-79aa9b7bf518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, None, 300)            9269700   ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, None, 300)            1107030   ['input_2[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 300),                721200    ['embedding[0][0]']           \n",
      "                              (None, 300),                                                        \n",
      "                              (None, 300)]                                                        \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, None, 300),          721200    ['embedding_1[0][0]',         \n",
      "                              (None, 300),                           'lstm[0][1]',                \n",
      "                              (None, 300)]                           'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 36901)          1110720   ['lstm_1[0][0]']              \n",
      "                                                          1                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 32889601 (125.46 MB)\n",
      "Trainable params: 32889601 (125.46 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a6070b-8c4a-47ea-9e3a-0dcb159a5e92",
   "metadata": {},
   "source": [
    "TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "425e0636-590f-4640-b590-39517bc6b3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2692bb6-6628-4230-9e54-9f50de377a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_generator = generate_batch(X_train, y_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab44a861-f023-4a90-b62b-f68b7d411c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('nmt_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb9f6557-4c97-4c4e-bf2a-8f3002ce5d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a029369-6594-44b4-a4a9-47da94d7a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "         # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7123b108-c197-406e-8b49-dd75311d86a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c263533-cca7-47ba-b959-6846d4dfa15c",
   "metadata": {},
   "source": [
    "RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f37d3d8-c05d-4128-ace8-0e3ea2b6f631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Input English sentence: were not just there for oil were there for lots of reasons\n",
      "Actual Hindi Translation:  हम वहापे सिर्फ आयल की वाज़ह्से नहीं है हम वहा और कई कारणों की वाज़ह्से है \n",
      "Predicted Hindi Translation:  कटौतीयों प्रयोजनों ho सुरों दिशाहीन अतीन्द्रिय दरव\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6b63aa06-b134-459a-a88a-5a1b74e94e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Input English sentence: if you will be working on average less than hours a week\n",
      "Actual Hindi Translation:  अगर आप सर्वसाधारण रुप से घंटे से कम काम कर रहे है तो \n",
      "Predicted Hindi Translation:  मिलताजुलता गीत खरीददारी अस्वीकर ‎आसान दौरानमुश\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7ddd4d5a-1f1a-407a-a919-925bb5e8e6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Input English sentence: have it so everyone sees who is the very best at teaching this stuff\n",
      "Actual Hindi Translation:  ताकि सब जान पाएँ कि इस बात को समझाने में कौन सबसे बेहतर है। \n",
      "Predicted Hindi Translation:  पायरिया इज्राएल सुधान कालान्तर विसंगति सुहा बी\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a053766-a1a0-48c2-bb5f-99870e84b160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
